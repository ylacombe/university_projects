{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Séparateurs à Vaste Marge - Yoach Lacombe et Wassim Lakehal\n",
    "\n",
    "Tout d'abord, importons les bibliothèques et la fonction utilisée dans le TP :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "from time import time\n",
    "\n",
    "def load_breastcancer(filename):\n",
    "    \"\"\"\n",
    "    Cette fonction lit le fichier filename, par exemple\n",
    "    filename = 'wdbc_M1_B0.data'\n",
    "    Elle retourne \n",
    "    X : une matrice de caracteristiques\n",
    "    y : un vecteur des classes tel que si y[i] = 1, la tumeur est maligne\n",
    "        et si y[i] = -1, la tumeur est benigne\n",
    "\n",
    "    Pour plus d'infos sur la base de donnees,\n",
    "    https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Prognostic%29\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.loadtxt(filename, delimiter=',')\n",
    "\n",
    "    # la colonne 0 ne nous interesse pas ici\n",
    "    y = data[:, 1] * 2 - 1\n",
    "    X = data[:, 2:]\n",
    "\n",
    "    # Standardisation de la matrice\n",
    "    X = X - np.mean(X, axis=0)\n",
    "    X = X / np.std(X, axis=0)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "X_tilda,Y = load_breastcancer(\"wdbcM1B0.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1\n",
    "Posons : $$ f(v,a,\\xi) = \\frac{1}{2}\\sum\\limits_{i=0}^mv_j^2 + c\\sum\\limits_{i=0}^n\\xi_i $$\n",
    "Et posons : $$ g(v,a) = \\frac{1}{2}\\sum\\limits_{i=0}^m v_j^2 +c\\sum\\limits_{i=0}^n max(0,1 - y_i(x_i^Tv+a))$$\n",
    "\n",
    "\n",
    "\n",
    "**Etape 1 :** \n",
    "Remarquons qu'avec $\\xi_i = max(0,1 - y_i(x_i^Tv+a))$, les $\\xi_i$ vérifient les contraintes : \n",
    "$ \\forall i \\in \\{1,...,n\\}$\n",
    ", $\\xi_i \\geq 0$ et  $\\xi_i \\geq 1 - y_i(x_i^Tv+a))$.\n",
    "\n",
    "Donc on a bien en notant $min_1$ le minimum du problème (1) et $min_2$ le minimum du problème (2) :\n",
    "$$\\forall(v,a),~~g(v,a) \\geq min_1$$\n",
    "Donc que : $ min_2 \\geq min_1 $.\n",
    "\n",
    "**Etape 2 :**\n",
    "Remarquons maintenant que, par propriété du minimum : \n",
    "$$ \\forall(v,a,\\xi),~ f(v,a,\\xi) \\geq min_{\\xi}f(v,a,\\xi)$$\n",
    "Donc, on a : \n",
    "$$ min_1 = min_{v,a,\\xi}f(v,a,\\xi) \\geq min_{v,a}[min_\\xi f(v,a,\\xi)]$$\n",
    "Or : $$min_\\xi f(v,a,\\xi) = g(v,a)$$\n",
    "En effet, on remarque que pour i donné, $\\xi \\geq min_\\xi \\xi$ et ici ce minimum est atteint en la borne inférieure de la définition de $\\xi$, c'est-à-dire en $max(0,1 - y_i(x_i^Tv+a)))$.\n",
    "\n",
    "En conclusion : $$min_1 \\geq min_{v,a}[g(v,a)] = min_2$$\n",
    "\n",
    "\n",
    "## Question 2.2\n",
    "\n",
    "Le résultat est direct pour tous points différents de $0$. En effet, la fonction est dérivable en tout point différent de 0 et donc le sous-gradient coïncide avec son gradient. Pour $z<0$, il n'y a donc que $\\{-1\\}$ et pour $z>0$, il n'y a que $\\{0\\}$ \n",
    "\n",
    "On représente (en vert) la courbe $y = max(0, 1-x)$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f04fe9436a0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def h(z):\n",
    "    return max(0,1-z)\n",
    "\n",
    "np.linspace(-5,5, 10)\n",
    "x = np.array([-5,1])\n",
    "x_bar = np.array([1,5])\n",
    "x_tot = np.array([-5,5])\n",
    "\n",
    "plt.plot(x, 1 - x, color = 'green', label = 'h(z) = 1-z')\n",
    "plt.plot(x_bar, [0,0], color = 'green')\n",
    "plt.plot([1, 5], [0, -4] , color = 'red', linestyle='dotted', label = 'min(1-z, z)')\n",
    "plt.plot([-5,1], [0,0] , color = 'red', linestyle='dotted')\n",
    "plt.plot(x_tot, 0.5*(1-x_tot), color = 'blue', linestyle='dotted', label = '0.5(1-z)')\n",
    "plt.plot(x_tot, 0.8*(1-x_tot), color = 'blue', linestyle='dotted', label = '0.8(1-z)')\n",
    "plt.plot(x_tot, 0.2*(1-x_tot), color = 'blue', linestyle='dotted', label = '0.2(1-z)')\n",
    "plt.title(\"Fonction h\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En $0$, on voit que pour toutes les droites de pente entre $-1$ et $0$ (les courbes bleues) se trouvent en dessous de la courbe verte donc le sous-gradient vaut en $0$ : $[-1, 0 ]$\n",
    "\n",
    "## Question 2.3\n",
    "On renomme notre précédente fonction g en f.\n",
    "    Avec $M = \\left( \\begin{array}{c}\n",
    "y_1x_1^T ~~~ y_1\\\\\n",
    "\\vdots \\\\\n",
    "y_ix_i^T ~~~ y_i  \\\\\n",
    "\\vdots \\\\\n",
    "y_nx_n^T ~~~ y_n\n",
    "\\end{array} \\right), ~~ N(v,a) = \\frac{1}{2}\\sum\\limits_{i=0}^mv_j^2~~ $et $ ~~ H(x) = \\sum\\limits_{i=0}^n h(x_i)$, on a bien ce que demande l'énoncé.\n",
    "\n",
    "De plus, on se convaint facilement que :\n",
    "$$ \\partial N(v,a) = \\left( \\begin{array}{c}\n",
    "v\\\\\n",
    "0\n",
    "\\end{array} \\right) $$\n",
    "En remarquant que H est séparable :\n",
    "$$ \\partial H(x) = \\partial h(x_1) \\times ... \\times \\partial h(x_n)$$\n",
    "\n",
    "\n",
    "## Question 2.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Rajoutons une colonne de 1 \n",
    "\n",
    "X = np.c_[X_tilda,np.ones((X_tilda.shape[0],1))]\n",
    "n,m = X.shape\n",
    "\n",
    "#Construction de M\n",
    "M = np.array([Y[i]*X[i,:] for i in range(n)])\n",
    "\n",
    "\n",
    "def fAndSubgrad(v,a):\n",
    "    N = M@((np.append(v,a)))\n",
    "    \n",
    "    h_ = [h(N[z]) for z in range(N.shape[0])]\n",
    "    \n",
    "    subgrad = np.append(v,0) + M.T@(subgrad_h(N))\n",
    "    value = v.T@v/2 + np.sum(h_)\n",
    "    \n",
    "    return value,subgrad\n",
    "\n",
    "\n",
    "def subgrad_h(x):\n",
    "    return -(x<=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "value, subgrad_value = fAndSubgrad(np.ones((m-1,1)), 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradientMethod(v_0,a_0,nb_iter):\n",
    "    v_k = v_0[:,0]\n",
    "    a_k = a_0\n",
    "    func_values = []\n",
    "    for k in range(nb_iter):\n",
    "\n",
    "        func_value, sub = fAndSubgrad(v_k,a_k)\n",
    "\n",
    "        v_k = v_k[:m-1] -sub[:m-1]/(k+1)\n",
    "        a_k = a_k -sub[-1]/(k+1)\n",
    "        func_values += [func_value]\n",
    "    return func_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeur : 26.570582119490382\n",
      "Temps d'exécution : 19.61750316619873\n"
     ]
    }
   ],
   "source": [
    "debut = time()\n",
    "print(\"Valeur :\", subgradientMethod(np.zeros((m-1,1)), 0,10000))\n",
    "print(\"Temps d'exécution :\", time()-debut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1\n",
    "\n",
    "Par la formule de transfert :\n",
    "$$ \\mathbb{E}[f_I(v,a)] = \\sum\\limits_{i=1}^n P(I=i)f_i(v,a) = \\frac{1}{n}\\sum\\limits_{i=1}^n f_i(v,a) = \\frac{1}{2}\\sum\\limits_{i=1}^m v_j^2 +\\frac{1}{n}cn\\sum\\limits_{i=1}^n max(0,1 - y_i(x_i^Tv+a)) = f(v,a) $$\n",
    "\n",
    "## Question 3.2\n",
    "\n",
    "Cette fois-ci, nous pouvons poser $M_i = \\left( \\begin{array}{c}\n",
    "0\\\\\n",
    "\\vdots \\\\\n",
    "(y_ix_i^T ~~~ y_i)  \\\\\n",
    "\\vdots \\\\\n",
    "0\n",
    "\\end{array} \\right)$ à la place de la matrice M et c$*$n à la place de c dans la formule du sous-gradient. D'où :\n",
    "$$ \\partial f_i(v,a) =  \\left( \\begin{array}{c}\n",
    "v\\\\\n",
    "0\n",
    "\\end{array} \\right)  + cnM_i^T \\partial H(M_i\\left( \\begin{array}{c}\n",
    "v\\\\\n",
    "a\n",
    "\\end{array} \\right)) \n",
    "= \\left( \\begin{array}{c}\n",
    "v\\\\\n",
    "0\n",
    "\\end{array} \\right)  + cnM_i^T \\partial H\\left( \\begin{array}{c}\n",
    "0\\\\\n",
    "\\vdots \\\\\n",
    "(y_ix_i^Tv + y_ia)  \\\\\n",
    "\\vdots \\\\\n",
    "0\n",
    "\\end{array} \\right)\n",
    "=\n",
    "\\left( \\begin{array}{c}\n",
    "v\\\\\n",
    "0\n",
    "\\end{array} \\right)  + cnM_i^T \\left( \\begin{array}{c}\n",
    "-1\\\\\n",
    "\\vdots \\\\\n",
    "\\partial h(y_ix_i^Tv + y_ia)  \\\\\n",
    "\\vdots \\\\\n",
    "-1\n",
    "\\end{array} \\right) $$\n",
    "$$\n",
    "=\n",
    "\\left( \\begin{array}{c}\n",
    "v\\\\\n",
    "0\n",
    "\\end{array} \\right)  + cny_i \\partial h(y_ix_i^Tv + y_ia) \\left( \\begin{array}{c}\n",
    "x_i\\\\\n",
    "1\n",
    "\\end{array} \\right)\n",
    "$$\n",
    "\n",
    "## Question 3.3\n",
    "\n",
    "Pour coder cette algorithme, nous allons tirer à chaque étape un $i_k$ et prendre $x_{k+1} = x_k - \\gamma_k g_k$ où $g_k \\in \\partial f_{i_k}(x_k)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def stochasticSubgradientMethod(v_0,a_0,nb_iter):\n",
    "    v_k = v_0[:,0]\n",
    "    a_k = a_0\n",
    "    func_values = []\n",
    "    total_step = 0\n",
    "    weighted_value_v = 0\n",
    "    weighted_value_a = 0\n",
    "    \n",
    "    for k in range(nb_iter):\n",
    "        #TIRER i dans {1,...,n}\n",
    "        i = randint(0,n-1)\n",
    "        func_value, sub = f_i_and_subgrad(v_k,a_k,i)\n",
    "        \n",
    "        step = (5*10**(-4))/np.sqrt(k+1)\n",
    "        \n",
    "        total_step += step\n",
    "        weighted_value_v += v_k*step\n",
    "        weighted_value_a += a_k*step\n",
    "        \n",
    "        \n",
    "        v_k = v_k[:m-1] -sub[:m-1]*step\n",
    "        \n",
    "        \n",
    "        a_k = a_k -sub[-1]*step\n",
    "        \n",
    "        func_values += [func_value]\n",
    "    \n",
    "    f_value,_ = fAndSubgrad(weighted_value_v/total_step , weighted_value_a/total_step)\n",
    "\n",
    "    return f_value\n",
    "\n",
    "\n",
    "def f_i_and_subgrad(v,a,i):\n",
    "    \n",
    "    subgrad = np.append(v,0) + n*Y[i]*subgrad_h(Y[i]*(X_tilda[i,:]@v + a))*np.append(X_tilda[i,:],1)\n",
    "    \n",
    "    value = v.T@v/2 + n * h(Y[i]*(X_tilda[i,:]@v + a))\n",
    "    \n",
    "    return value,subgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeur : 36.908097636012165\n",
      "Temps d'exécution : 0.46237707138061523\n"
     ]
    }
   ],
   "source": [
    "debut = time()\n",
    "print(\"Valeur :\", stochasticSubgradientMethod(np.zeros((m-1,1)), 0,10000))\n",
    "print(\"Temps d'exécution :\", time()-debut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.1\n",
    "\n",
    "Avec $\\phi \\in \\textbf{R}^{2n}$ :\n",
    "$$ L(v,\\xi, \\phi) = \\frac{1}{2}\\sum\\limits_{i=0}^mv_j^2 + c\\sum\\limits_{i=0}^n\\xi_i + \\sum\\limits_{i=0}^n[ -\\xi_i\\phi_i +\\phi_{i+n}(1 - y_{i+n}(x_{i+n}^Tv+a) - \\xi_{i+n})] - \\sum\\limits_{i=0}^{2n} \\iota_{\\textbf{R}_+}(\\phi_i) $$\n",
    "\n",
    "## Question 4.2\n",
    "\n",
    "Remarquons que \"$ x : \\mapsto max(0,x)^2$\" est une fonction continuement dérivable en 0 (on prolonge la dérivé par continuité en 0), de dérivée : \"$ x : \\mapsto 2max(0,x)$\".\n",
    "\n",
    "Ainsi, par dérivées de fonctions composées :\n",
    "$$ \\nabla_xg(x,\\phi) = \\rho max(0,x + \\rho^{-1}\\phi)$$\n",
    "Et : \n",
    "$$ \\nabla_{\\phi}g(x,\\phi) = -\\rho^{-1}\\phi + \\frac{\\rho}{\\rho} max(0,x + \\rho^{-1}\\phi) = max(-\\rho^{-1}\\phi,x )$$\n",
    "\n",
    "## Question 4.3\n",
    "$ x \\mapsto \\nabla_xg(x,\\phi) $ est donc croissante sur l'ensemble des réels, on a donc la convexité de $x \\mapsto g(x,\\phi)$.\n",
    "\n",
    "De plus, $ \\phi \\mapsto \\nabla_xg(x,\\phi) $ est décroissante sur l'ensemble des réels, on a donc la concavité de $\\phi \\mapsto g(x,\\phi)$.\n",
    "\n",
    "## Question 4.4\n",
    "\n",
    "On calcule d'abord les gradients de la Lagrangienne par rapport à v,a et $\\xi$:\n",
    "$$ \\nabla_vL(v,a,\\xi,\\phi,\\psi) = v - \\sum\\limits_{i=1}^n y_ix_i \\rho max(0, -\\xi_i + 1 - y_{i}(x_{i}^Tv+a) + \\phi_i\\rho^{-1})$$ \n",
    "$$ \\nabla_aL(v,a,\\xi,\\phi,\\psi) = - \\sum\\limits_{i=1}^n y_i \\rho max(0, -\\xi_i + 1 - y_{i}(x_{i}^Tv+a) + \\phi_i\\rho^{-1})$$ \n",
    "$$ \\nabla_{\\xi}L(v,a,\\xi,\\phi,\\psi) = c - (\\rho max(0, \\rho^{-1}\\phi_i - \\xi_i))_i- ( \\rho max(0, -\\xi_i + 1 - y_{i}(x_{i}^Tv+a) + \\phi_i\\rho^{-1}))_i$$ \n",
    "\n",
    "D'où la méthode du gradient, ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_x_g(x,phi,rho):\n",
    "    return rho * np.maximum(0, x + phi/rho)\n",
    "\n",
    "\n",
    "def gradient_lagrangien(phi,psi,condition_arret,rho):\n",
    "    v,a,xi = np.zeros(m-1),condition_arret + 1 , np.zeros(n)\n",
    "    \n",
    "    N = 1 - M@((np.append(v,a)))\n",
    "\n",
    "\n",
    "    grad_v = v - (M.T@grad_x_g(N-xi,phi,rho))[:-1]\n",
    "    grad_a = - Y.T@grad_x_g(N-xi,phi,rho)     \n",
    "    grad_xi = 1 - grad_x_g(-xi,phi,rho) - grad_x_g(N-xi,phi,rho)\n",
    "\n",
    "    norm = grad_a**2 + np.sum(grad_v**2) + np.sum(grad_xi**2)\n",
    "    k=1\n",
    "    while (norm > condition_arret**2):\n",
    "        grad_v = v - (M.T@grad_x_g(N-xi,phi,rho))[:-1]\n",
    "        grad_a = - Y.T@grad_x_g(N-xi,phi,rho)     \n",
    "        grad_xi = 1 - grad_x_g(-xi,phi,rho) - grad_x_g(N-xi,phi,rho)\n",
    "         \n",
    "        norm = grad_a**2 + np.sum(grad_v**2) + np.sum(grad_xi**2)\n",
    "        v = v - grad_v/750     \n",
    "        a = a - grad_a/750         \n",
    "        xi = xi - grad_xi/750\n",
    "        N = 1- M@((np.append(v,a)))\n",
    "\n",
    "        k+=1\n",
    "            \n",
    "    return v,a,xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.5\n",
    "\n",
    "\n",
    "$$ \\nabla_{\\phi}L(v,a,\\xi,\\phi,\\psi) = (max( - \\frac{\\phi_i}{\\rho}, -\\xi_i))$$ \n",
    "$$ \\nabla_{\\psi}L(v,a,\\xi,\\phi,\\psi) = (max( - \\frac{\\psi_i}{\\rho}, -\\xi_i + 1 - y_{i}(x_{i}^Tv+a)))$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_phi_g(x,phi,rho):\n",
    "    return np.maximum(-phi/rho, x)\n",
    "\n",
    "def grad_phi_psi(v,a,xi,phi,psi,rho):\n",
    "    N = M@((np.append(v,a)))\n",
    "    \n",
    "    \n",
    "    grad_phi = grad_phi_g(-xi,phi,rho)\n",
    "    \n",
    "    grad_psi = grad_phi_g(-xi + 1- N ,psi,rho)\n",
    "    \n",
    "    return grad_phi, grad_psi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ALM(phi0, psi0, condition_arret = 1, rho = 2, nb_iterations  = 2000):\n",
    "    \n",
    "    phi,psi = phi0,psi0\n",
    "    \n",
    "    for k in range(nb_iterations):\n",
    "        v,a,xi = gradient_lagrangien(phi,psi,condition_arret, condition_arret)\n",
    "        \n",
    "        grad_phi, grad_psi = grad_phi_psi(v,a,xi,phi,psi,rho)\n",
    "        phi += rho*grad_phi\n",
    "        psi += rho*grad_psi\n",
    "    \n",
    "    return v,a,xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution : 629.9421944618225\n"
     ]
    }
   ],
   "source": [
    "debut = time()\n",
    "test_v,test_a,test_xi = ALM(np.zeros(n),np.zeros(n))\n",
    "print(\"Temps d'exécution :\", time()-debut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.162495675697487"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_v.T@test_v/2  + np.sum(test_xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28.464571080831973,\n",
       " array([ 1.16933323,  1.26088753,  1.00518502,  1.2923403 , -0.54094765,\n",
       "        -2.08829148, -1.55803491,  0.078724  ,  0.43130691, -2.73454178,\n",
       "         3.48912349,  1.81649251,  3.3597331 ,  2.18732888, -1.24417101,\n",
       "        -2.42963447, -3.05643706,  0.01012139, -1.02500591, -1.18282814,\n",
       "         1.21371166, -0.00575283,  1.14693168,  1.16920323, -3.80617076,\n",
       "        -3.28203098, -3.97157108, -1.18369923, -1.62633202, -3.7666303 ,\n",
       "        -2.        ]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fAndSubgrad(test_v,test_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5.1\n",
    "\n",
    "Comparons finalement les résultats :\n",
    "\n",
    "Tout d'abord, nous pouvons entrer dans le tableau suivant le temps d'exécution et la valeur finale que renvoie chaque algorithme :\n",
    "\n",
    "|  | Méthode du sous-gradient classique |  Méthode du sous-gradient stochastique  | Méthode du lagrangien augmenté  |   |\n",
    "|---|---|---|:-:|---|\n",
    "| Résultat final  | 26.570582119490382 | 36.908097636012165 | 28.464571080831973   |   |\n",
    "| Temps d'exéution  | 19.61750316619873 | 0.46237707138061523 | 629.9421944618225 |   |\n",
    "\n",
    "Il semblerait que la méthode du lagrangien augmenté n'est pas la meilleure méthode car elle ne produit ni le résultat le plus rapide, ni le meilleur résultat.\n",
    "\n",
    "En revanche, la méthode du sous-gradient stochastique renvoie un résultat aléatoire à chaque itération et celui-ci (bien qu'il soit rapide) n'est pas meilleur en moyenne que celui fournit par la méthode du sous-gradient classique. En effet, en effectuant $10^6$ itérations du sous-gradient stochastique, le résultat final tourne en moyenne autour de $27$ mais prend $44$ secondes. Ainsi, dans ce cas, l'algorithme de la méthode du sous-gradient stochastiqu efournit un moins bon résultat que la méthode du sous-gradient classique en plus de temps. L'algorithme du sous-gradient stochastique pourrait probablement être amélioré en prenant un sous ensemble de $f_i$ plutot qu'une seule valeur.\n",
    "\n",
    "En définitive, il apparaît que la meilleure fonction à utiliser est la première."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
